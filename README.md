# AIMAS Recommendation Service

A microservice within the **AIMAS (AI-based Incident Management and Alert System)** ecosystem.  

This service listens to live system or application metrics published by the **Log Management** component through **RabbitMQ**, analyzes them using either **rule-based logic** or **LLM-based reasoning**, and publishes actionable **recommendations** to other AIMAS services such as **Alerts**, **Dashboards**, or **Reports**.

---

## Data Flow Overview

```
Prometheus ‚Üí Log Management ‚Üí [RabbitMQ Exchange: logs]
                     ‚Üì
         AIMAS Recommendation Service
   ‚îú‚îÄ consumer.py      ‚Üí rule-based & AI/LLM-driven analysis
                     ‚Üì
         [RabbitMQ Exchange: recommendations]
                     ‚Üì
          Alerts / Dashboard / Reports
```

---

## Key Features

- **Dual Mode Analysis** ‚Äî choose between rule-based or AI-powered recommendations  
- **RabbitMQ Integration** ‚Äî consumes from `logs` exchange, publishes to `recommendations`  
- **Metric Coverage** ‚Äî CPU, memory, disk, network, and service performance events  
- **FastAPI Health Endpoints** ‚Äî `/health/live`, `/health/ready`  
- ü™∂ **Lightweight & Container-Ready** ‚Äî minimal dependencies, plug-and-play  

---

## üóÇÔ∏è Project Structure

```
aima-recommendation-service/
‚îú‚îÄ‚îÄ app.py                  # FastAPI app (health endpoints)
‚îú‚îÄ‚îÄ consumer.py             # Rule & OpenAI-based recommendation worker
‚îú‚îÄ‚îÄ rabbitmq_publisher.py   # Shared publisher utility
‚îú‚îÄ‚îÄ rules/                  # Modular rule packs (CPU, network, etc.)
‚îú‚îÄ‚îÄ .env                    # Environment configuration
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îî‚îÄ‚îÄ Prometheus_win_exporter_rabbitmq.md  # Step-by-step setup guide
```

---

## Environment Variables (`.env`)

```bash
# RabbitMQ connection
RABBIT_URL=amqp://guest:guest@localhost:5672/%2F

# Exchanges
RABBIT_LOG_EXCHANGE=logs
RABBIT_RECO_EXCHANGE=recommendations

# Queues
RABBIT_LOG_QUEUE=reco.logs

# Optional service metadata
SERVICE_VERSION=0.1.0
```

---

## Requirements

- **Python 3.9+**
- **RabbitMQ** (local or central broker)
- **Prometheus + Windows Exporter** (for metrics collection)  
  üëâ For a detailed installation guide, see  
  **[`Prometheus_win_exporter_rabbitmq.md`](Prometheus_win_exporter_rabbitmq.md)**

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ‚ñ∂Ô∏è Running the Service

### 1. Start the Health API

```bash
uvicorn app:app --host 0.0.0.0 --port 8080 --reload
```

- **Liveness:**‚ÄÉ`GET http://localhost:8080/health/live`  
- **Readiness:** `GET http://localhost:8080/health/ready` (also checks RabbitMQ)

### 2. Start the Rule-Based Worker

```bash
python consumer.py
```

### 3. Start the AI/LLM Worker (optional)

```bash
python consumer_llm.py
```

> The LLM worker uses your `OPENAI_API_KEY` and prints the generated recommendations directly to your terminal.

---

## ü©∫ Health Endpoints

| Endpoint | Purpose | RabbitMQ Required |
|-----------|----------|------------------|
| `/health/live` | Process liveness check | ‚ùå |
| `/health/ready` | Readiness & RabbitMQ connectivity | ‚úÖ (optional) |

---

## Future Enhancements

- Integrate NoSQL storage for recommendation history  
- Add vector search for similar incident detection  
- Enhance AI model context awareness and confidence scoring  

---

## Contributors
- Chima Enyeribe  
- Oluwatobilola Jesse  
- McAdams  

---

## License
MIT License ¬© 2025 AIMAS Development Team  
